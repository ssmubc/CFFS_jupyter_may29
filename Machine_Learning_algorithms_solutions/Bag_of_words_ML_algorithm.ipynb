{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4842e797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "141a766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803300bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phrases = [\"The quick brown fox jumped over the lazy dog\",\n",
    "#           \"education is what you have left over after forgetting everything you\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f38da6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vect = CountVectorizer()\n",
    "# vect.fit(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c271a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gives us the size of unique words in our vocabulary (phrase)\n",
    "# print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "\n",
    "# # Each word with its assigned index, how the word is represented \n",
    "# print(\"Vocabulary content:\\n {}\".format(vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357d3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag_of_words = vect.transform(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c305cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuple (training example number, index assigned to the word)\n",
    "# print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a9d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"bag_of_words as an array:\\n{}\".format(bag_of_words.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef59ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bf1d985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a59061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "from sklearn.compose import (\n",
    "    ColumnTransformer,\n",
    "    TransformedTargetRegressor,\n",
    "    make_column_transformer,\n",
    ")\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, RidgeCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f802496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"C:/Users/smvan/CFFS-S23/CFFS-22-23/data/Machine_Learning_model/Updated_data_Gather22-23_BagOW.csv\")\n",
    "\n",
    "data = pd.read_csv(\"C:/Users/smvan/CFFS-S23/CFFS-22-23/data/Machine_Learning_model/Data_Labelled_Gather22-23_with_name.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93b1dbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Displayed Name</th>\n",
       "      <th>ProdId</th>\n",
       "      <th>Description</th>\n",
       "      <th>SalesGroup</th>\n",
       "      <th>Weight (g)</th>\n",
       "      <th>GHG Emission (g)</th>\n",
       "      <th>N lost (g)</th>\n",
       "      <th>Land Use (m^2)</th>\n",
       "      <th>Freshwater Withdrawals (L)</th>\n",
       "      <th>...</th>\n",
       "      <th>GHG Emission (g) / 100g</th>\n",
       "      <th>N lost (g) / 100g</th>\n",
       "      <th>Freshwater Withdrawals (L) / 100g</th>\n",
       "      <th>Stress-Weighted Water Use (L) / 100g</th>\n",
       "      <th>Land Use (m^2) / 100g</th>\n",
       "      <th>GHG Only Label</th>\n",
       "      <th>Combined Label</th>\n",
       "      <th>RED</th>\n",
       "      <th>YELLOW</th>\n",
       "      <th>GREEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caliente</td>\n",
       "      <td>Black bean soup</td>\n",
       "      <td>R-54947</td>\n",
       "      <td>CAL|Black bean soup|AAD</td>\n",
       "      <td>GV - CALIENTE</td>\n",
       "      <td>405.0</td>\n",
       "      <td>642.872062</td>\n",
       "      <td>3.699893</td>\n",
       "      <td>3.714369</td>\n",
       "      <td>53.60</td>\n",
       "      <td>...</td>\n",
       "      <td>158.73</td>\n",
       "      <td>0.91</td>\n",
       "      <td>13.23</td>\n",
       "      <td>425.48</td>\n",
       "      <td>0.92</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caliente</td>\n",
       "      <td>Guacamole bowl</td>\n",
       "      <td>R-55154</td>\n",
       "      <td>CAL|Bowl|Guacamole|AAD</td>\n",
       "      <td>GV - CALIENTE</td>\n",
       "      <td>345.0</td>\n",
       "      <td>577.312312</td>\n",
       "      <td>3.412346</td>\n",
       "      <td>1.652956</td>\n",
       "      <td>115.97</td>\n",
       "      <td>...</td>\n",
       "      <td>167.34</td>\n",
       "      <td>0.99</td>\n",
       "      <td>33.61</td>\n",
       "      <td>881.02</td>\n",
       "      <td>0.48</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caliente</td>\n",
       "      <td>Havana Add Chicken Bowl</td>\n",
       "      <td>R-62018</td>\n",
       "      <td>CAL|Bowl|Havana|Add Chicken</td>\n",
       "      <td>GV - CALIENTE</td>\n",
       "      <td>430.0</td>\n",
       "      <td>1036.107243</td>\n",
       "      <td>15.532360</td>\n",
       "      <td>3.663406</td>\n",
       "      <td>125.84</td>\n",
       "      <td>...</td>\n",
       "      <td>240.96</td>\n",
       "      <td>3.61</td>\n",
       "      <td>29.27</td>\n",
       "      <td>177.77</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caliente</td>\n",
       "      <td>Havana Add Scallop Bowl</td>\n",
       "      <td>R-64909</td>\n",
       "      <td>CAL|Bowl|Havana|Add Scallop</td>\n",
       "      <td>GV - CALIENTE</td>\n",
       "      <td>390.0</td>\n",
       "      <td>658.333777</td>\n",
       "      <td>6.220997</td>\n",
       "      <td>2.299315</td>\n",
       "      <td>83.40</td>\n",
       "      <td>...</td>\n",
       "      <td>168.80</td>\n",
       "      <td>1.60</td>\n",
       "      <td>21.38</td>\n",
       "      <td>173.71</td>\n",
       "      <td>0.59</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caliente</td>\n",
       "      <td>Havana Plant-based Bowl</td>\n",
       "      <td>R-35896</td>\n",
       "      <td>CAL|Bowl|Havana|Plant based</td>\n",
       "      <td>GV - CALIENTE</td>\n",
       "      <td>415.0</td>\n",
       "      <td>685.178688</td>\n",
       "      <td>2.802186</td>\n",
       "      <td>2.710241</td>\n",
       "      <td>83.81</td>\n",
       "      <td>...</td>\n",
       "      <td>165.10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>20.20</td>\n",
       "      <td>162.22</td>\n",
       "      <td>0.65</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category            Displayed Name   ProdId                  Description  \\\n",
       "0  Caliente            Black bean soup  R-54947      CAL|Black bean soup|AAD   \n",
       "1  Caliente             Guacamole bowl  R-55154       CAL|Bowl|Guacamole|AAD   \n",
       "2  Caliente    Havana Add Chicken Bowl  R-62018  CAL|Bowl|Havana|Add Chicken   \n",
       "3  Caliente    Havana Add Scallop Bowl  R-64909  CAL|Bowl|Havana|Add Scallop   \n",
       "4  Caliente    Havana Plant-based Bowl  R-35896  CAL|Bowl|Havana|Plant based   \n",
       "\n",
       "      SalesGroup  Weight (g)  GHG Emission (g)  N lost (g)  Land Use (m^2)  \\\n",
       "0  GV - CALIENTE       405.0        642.872062    3.699893        3.714369   \n",
       "1  GV - CALIENTE       345.0        577.312312    3.412346        1.652956   \n",
       "2  GV - CALIENTE       430.0       1036.107243   15.532360        3.663406   \n",
       "3  GV - CALIENTE       390.0        658.333777    6.220997        2.299315   \n",
       "4  GV - CALIENTE       415.0        685.178688    2.802186        2.710241   \n",
       "\n",
       "   Freshwater Withdrawals (L)  ...  GHG Emission (g) / 100g  \\\n",
       "0                       53.60  ...                   158.73   \n",
       "1                      115.97  ...                   167.34   \n",
       "2                      125.84  ...                   240.96   \n",
       "3                       83.40  ...                   168.80   \n",
       "4                       83.81  ...                   165.10   \n",
       "\n",
       "   N lost (g) / 100g  Freshwater Withdrawals (L) / 100g  \\\n",
       "0               0.91                              13.23   \n",
       "1               0.99                              33.61   \n",
       "2               3.61                              29.27   \n",
       "3               1.60                              21.38   \n",
       "4               0.68                              20.20   \n",
       "\n",
       "   Stress-Weighted Water Use (L) / 100g  Land Use (m^2) / 100g  \\\n",
       "0                                425.48                   0.92   \n",
       "1                                881.02                   0.48   \n",
       "2                                177.77                   0.85   \n",
       "3                                173.71                   0.59   \n",
       "4                                162.22                   0.65   \n",
       "\n",
       "   GHG Only Label Combined Label  RED YELLOW GREEN  \n",
       "0           Green          Green  NaN    NaN  True  \n",
       "1           Green          Green  NaN    NaN  True  \n",
       "2          Yellow         Yellow  NaN   True   NaN  \n",
       "3           Green          Green  NaN    NaN  True  \n",
       "4           Green          Green  NaN    NaN  True  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f59cbb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Green     134\n",
       "Yellow     97\n",
       "Red        72\n",
       "Name: Combined Label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Combined Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a172321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b40e864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Displayed Name</th>\n",
       "      <th>ProdId</th>\n",
       "      <th>Description</th>\n",
       "      <th>SalesGroup</th>\n",
       "      <th>Weight (g)</th>\n",
       "      <th>GHG Emission (g)</th>\n",
       "      <th>N lost (g)</th>\n",
       "      <th>Land Use (m^2)</th>\n",
       "      <th>Freshwater Withdrawals (L)</th>\n",
       "      <th>...</th>\n",
       "      <th>GHG Emission (g) / 100g</th>\n",
       "      <th>N lost (g) / 100g</th>\n",
       "      <th>Freshwater Withdrawals (L) / 100g</th>\n",
       "      <th>Stress-Weighted Water Use (L) / 100g</th>\n",
       "      <th>Land Use (m^2) / 100g</th>\n",
       "      <th>GHG Only Label</th>\n",
       "      <th>Combined Label</th>\n",
       "      <th>RED</th>\n",
       "      <th>YELLOW</th>\n",
       "      <th>GREEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Fresh Fare AM</td>\n",
       "      <td>Mushroom garlic Toast</td>\n",
       "      <td>R-61874</td>\n",
       "      <td>FF|Toast|Mushroom toast|AAD</td>\n",
       "      <td>GV FRESH FARE DAY</td>\n",
       "      <td>169.187500</td>\n",
       "      <td>366.529727</td>\n",
       "      <td>3.001152</td>\n",
       "      <td>0.968973</td>\n",
       "      <td>29.80</td>\n",
       "      <td>...</td>\n",
       "      <td>216.64</td>\n",
       "      <td>1.77</td>\n",
       "      <td>17.61</td>\n",
       "      <td>733.14</td>\n",
       "      <td>0.57</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Grill PM</td>\n",
       "      <td>Monte Cristo</td>\n",
       "      <td>R-56456</td>\n",
       "      <td>GRL|Sand|Monte Cristo|AAD</td>\n",
       "      <td>GV - GRILL BREAKFAST</td>\n",
       "      <td>298.000001</td>\n",
       "      <td>1399.792852</td>\n",
       "      <td>21.989216</td>\n",
       "      <td>3.125298</td>\n",
       "      <td>208.15</td>\n",
       "      <td>...</td>\n",
       "      <td>469.73</td>\n",
       "      <td>7.38</td>\n",
       "      <td>69.85</td>\n",
       "      <td>2125.27</td>\n",
       "      <td>1.05</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Grill PM</td>\n",
       "      <td>Jelepeno grilled cheese</td>\n",
       "      <td>R-50668</td>\n",
       "      <td>GRL|Grilled Cheese|Jalapeno</td>\n",
       "      <td>GV GRILL FEATURE</td>\n",
       "      <td>191.000001</td>\n",
       "      <td>655.889109</td>\n",
       "      <td>6.801639</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>110.04</td>\n",
       "      <td>...</td>\n",
       "      <td>343.40</td>\n",
       "      <td>3.56</td>\n",
       "      <td>57.61</td>\n",
       "      <td>2814.95</td>\n",
       "      <td>0.46</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Red</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Delish</td>\n",
       "      <td>Delish Blueberry</td>\n",
       "      <td>R-36817</td>\n",
       "      <td>DEL|Smoothie|Delish</td>\n",
       "      <td>GV - DELISH</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.867474</td>\n",
       "      <td>0.012589</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.41</td>\n",
       "      <td>...</td>\n",
       "      <td>286.75</td>\n",
       "      <td>1.26</td>\n",
       "      <td>41.00</td>\n",
       "      <td>1740.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Grill PM</td>\n",
       "      <td>Poutine Gravy</td>\n",
       "      <td>R-44765</td>\n",
       "      <td>ADD|Gravy|3oz</td>\n",
       "      <td>GV GRILL DAY</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>79.505397</td>\n",
       "      <td>0.765742</td>\n",
       "      <td>0.115836</td>\n",
       "      <td>9.05</td>\n",
       "      <td>...</td>\n",
       "      <td>88.34</td>\n",
       "      <td>0.85</td>\n",
       "      <td>10.06</td>\n",
       "      <td>439.87</td>\n",
       "      <td>0.13</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Category            Displayed Name   ProdId  \\\n",
       "132  Fresh Fare AM      Mushroom garlic Toast  R-61874   \n",
       "202       Grill PM               Monte Cristo  R-56456   \n",
       "196       Grill PM    Jelepeno grilled cheese  R-50668   \n",
       "75          Delish           Delish Blueberry  R-36817   \n",
       "176       Grill PM              Poutine Gravy  R-44765   \n",
       "\n",
       "                     Description            SalesGroup  Weight (g)  \\\n",
       "132  FF|Toast|Mushroom toast|AAD     GV FRESH FARE DAY  169.187500   \n",
       "202    GRL|Sand|Monte Cristo|AAD  GV - GRILL BREAKFAST  298.000001   \n",
       "196  GRL|Grilled Cheese|Jalapeno      GV GRILL FEATURE  191.000001   \n",
       "75           DEL|Smoothie|Delish           GV - DELISH    1.000000   \n",
       "176                ADD|Gravy|3oz          GV GRILL DAY   90.000000   \n",
       "\n",
       "     GHG Emission (g)  N lost (g)  Land Use (m^2)  Freshwater Withdrawals (L)  \\\n",
       "132        366.529727    3.001152        0.968973                       29.80   \n",
       "202       1399.792852   21.989216        3.125298                      208.15   \n",
       "196        655.889109    6.801639        0.887445                      110.04   \n",
       "75           2.867474    0.012589        0.002809                        0.41   \n",
       "176         79.505397    0.765742        0.115836                        9.05   \n",
       "\n",
       "     ...  GHG Emission (g) / 100g  N lost (g) / 100g  \\\n",
       "132  ...                   216.64               1.77   \n",
       "202  ...                   469.73               7.38   \n",
       "196  ...                   343.40               3.56   \n",
       "75   ...                   286.75               1.26   \n",
       "176  ...                    88.34               0.85   \n",
       "\n",
       "     Freshwater Withdrawals (L) / 100g  Stress-Weighted Water Use (L) / 100g  \\\n",
       "132                              17.61                                733.14   \n",
       "202                              69.85                               2125.27   \n",
       "196                              57.61                               2814.95   \n",
       "75                               41.00                               1740.00   \n",
       "176                              10.06                                439.87   \n",
       "\n",
       "     Land Use (m^2) / 100g  GHG Only Label Combined Label   RED YELLOW GREEN  \n",
       "132                   0.57          Yellow         Yellow   NaN   True   NaN  \n",
       "202                   1.05             Red            Red  True    NaN   NaN  \n",
       "196                   0.46          Yellow            Red  True    NaN   NaN  \n",
       "75                    0.28          Yellow         Yellow   NaN   True   NaN  \n",
       "176                   0.13           Green          Green   NaN    NaN  True  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c564d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text by separating words using the \"|\" delimiter\n",
    "import re\n",
    "\n",
    "# Preprocess the text by separating words using the \"|\" delimiter\n",
    "train_df[\"Description\"] = train_df[\"Description\"].apply(lambda x: re.sub(r'\\|', ' ', x))\n",
    "test_df[\"Description\"] = test_df[\"Description\"].apply(lambda x: re.sub(r'\\|', ' ', x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "812fe931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Displayed Name</th>\n",
       "      <th>ProdId</th>\n",
       "      <th>Description</th>\n",
       "      <th>SalesGroup</th>\n",
       "      <th>Weight (g)</th>\n",
       "      <th>GHG Emission (g)</th>\n",
       "      <th>N lost (g)</th>\n",
       "      <th>Land Use (m^2)</th>\n",
       "      <th>Freshwater Withdrawals (L)</th>\n",
       "      <th>...</th>\n",
       "      <th>GHG Emission (g) / 100g</th>\n",
       "      <th>N lost (g) / 100g</th>\n",
       "      <th>Freshwater Withdrawals (L) / 100g</th>\n",
       "      <th>Stress-Weighted Water Use (L) / 100g</th>\n",
       "      <th>Land Use (m^2) / 100g</th>\n",
       "      <th>GHG Only Label</th>\n",
       "      <th>Combined Label</th>\n",
       "      <th>RED</th>\n",
       "      <th>YELLOW</th>\n",
       "      <th>GREEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Fresh Fare AM</td>\n",
       "      <td>Mushroom garlic Toast</td>\n",
       "      <td>R-61874</td>\n",
       "      <td>FF Toast Mushroom toast AAD</td>\n",
       "      <td>GV FRESH FARE DAY</td>\n",
       "      <td>169.187500</td>\n",
       "      <td>366.529727</td>\n",
       "      <td>3.001152</td>\n",
       "      <td>0.968973</td>\n",
       "      <td>29.80</td>\n",
       "      <td>...</td>\n",
       "      <td>216.64</td>\n",
       "      <td>1.77</td>\n",
       "      <td>17.61</td>\n",
       "      <td>733.14</td>\n",
       "      <td>0.57</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Grill PM</td>\n",
       "      <td>Monte Cristo</td>\n",
       "      <td>R-56456</td>\n",
       "      <td>GRL Sand Monte Cristo AAD</td>\n",
       "      <td>GV - GRILL BREAKFAST</td>\n",
       "      <td>298.000001</td>\n",
       "      <td>1399.792852</td>\n",
       "      <td>21.989216</td>\n",
       "      <td>3.125298</td>\n",
       "      <td>208.15</td>\n",
       "      <td>...</td>\n",
       "      <td>469.73</td>\n",
       "      <td>7.38</td>\n",
       "      <td>69.85</td>\n",
       "      <td>2125.27</td>\n",
       "      <td>1.05</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Grill PM</td>\n",
       "      <td>Jelepeno grilled cheese</td>\n",
       "      <td>R-50668</td>\n",
       "      <td>GRL Grilled Cheese Jalapeno</td>\n",
       "      <td>GV GRILL FEATURE</td>\n",
       "      <td>191.000001</td>\n",
       "      <td>655.889109</td>\n",
       "      <td>6.801639</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>110.04</td>\n",
       "      <td>...</td>\n",
       "      <td>343.40</td>\n",
       "      <td>3.56</td>\n",
       "      <td>57.61</td>\n",
       "      <td>2814.95</td>\n",
       "      <td>0.46</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Red</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Delish</td>\n",
       "      <td>Delish Blueberry</td>\n",
       "      <td>R-36817</td>\n",
       "      <td>DEL Smoothie Delish</td>\n",
       "      <td>GV - DELISH</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.867474</td>\n",
       "      <td>0.012589</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.41</td>\n",
       "      <td>...</td>\n",
       "      <td>286.75</td>\n",
       "      <td>1.26</td>\n",
       "      <td>41.00</td>\n",
       "      <td>1740.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Grill PM</td>\n",
       "      <td>Poutine Gravy</td>\n",
       "      <td>R-44765</td>\n",
       "      <td>ADD Gravy 3oz</td>\n",
       "      <td>GV GRILL DAY</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>79.505397</td>\n",
       "      <td>0.765742</td>\n",
       "      <td>0.115836</td>\n",
       "      <td>9.05</td>\n",
       "      <td>...</td>\n",
       "      <td>88.34</td>\n",
       "      <td>0.85</td>\n",
       "      <td>10.06</td>\n",
       "      <td>439.87</td>\n",
       "      <td>0.13</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Category            Displayed Name   ProdId  \\\n",
       "132  Fresh Fare AM      Mushroom garlic Toast  R-61874   \n",
       "202       Grill PM               Monte Cristo  R-56456   \n",
       "196       Grill PM    Jelepeno grilled cheese  R-50668   \n",
       "75          Delish           Delish Blueberry  R-36817   \n",
       "176       Grill PM              Poutine Gravy  R-44765   \n",
       "\n",
       "                     Description            SalesGroup  Weight (g)  \\\n",
       "132  FF Toast Mushroom toast AAD     GV FRESH FARE DAY  169.187500   \n",
       "202    GRL Sand Monte Cristo AAD  GV - GRILL BREAKFAST  298.000001   \n",
       "196  GRL Grilled Cheese Jalapeno      GV GRILL FEATURE  191.000001   \n",
       "75           DEL Smoothie Delish           GV - DELISH    1.000000   \n",
       "176                ADD Gravy 3oz          GV GRILL DAY   90.000000   \n",
       "\n",
       "     GHG Emission (g)  N lost (g)  Land Use (m^2)  Freshwater Withdrawals (L)  \\\n",
       "132        366.529727    3.001152        0.968973                       29.80   \n",
       "202       1399.792852   21.989216        3.125298                      208.15   \n",
       "196        655.889109    6.801639        0.887445                      110.04   \n",
       "75           2.867474    0.012589        0.002809                        0.41   \n",
       "176         79.505397    0.765742        0.115836                        9.05   \n",
       "\n",
       "     ...  GHG Emission (g) / 100g  N lost (g) / 100g  \\\n",
       "132  ...                   216.64               1.77   \n",
       "202  ...                   469.73               7.38   \n",
       "196  ...                   343.40               3.56   \n",
       "75   ...                   286.75               1.26   \n",
       "176  ...                    88.34               0.85   \n",
       "\n",
       "     Freshwater Withdrawals (L) / 100g  Stress-Weighted Water Use (L) / 100g  \\\n",
       "132                              17.61                                733.14   \n",
       "202                              69.85                               2125.27   \n",
       "196                              57.61                               2814.95   \n",
       "75                               41.00                               1740.00   \n",
       "176                              10.06                                439.87   \n",
       "\n",
       "     Land Use (m^2) / 100g  GHG Only Label Combined Label   RED YELLOW GREEN  \n",
       "132                   0.57          Yellow         Yellow   NaN   True   NaN  \n",
       "202                   1.05             Red            Red  True    NaN   NaN  \n",
       "196                   0.46          Yellow            Red  True    NaN   NaN  \n",
       "75                    0.28          Yellow         Yellow   NaN   True   NaN  \n",
       "176                   0.13           Green          Green   NaN    NaN  True  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "415d5f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Displayed Name', 'ProdId', 'Description', 'SalesGroup',\n",
       "       'Weight (g)', 'GHG Emission (g)', 'N lost (g)', 'Land Use (m^2)',\n",
       "       'Freshwater Withdrawals (L)', 'Stress-Weighted Water Use (L)',\n",
       "       'GHG Emission (g) / 100g', 'N lost (g) / 100g',\n",
       "       'Freshwater Withdrawals (L) / 100g',\n",
       "       'Stress-Weighted Water Use (L) / 100g', 'Land Use (m^2) / 100g',\n",
       "       'GHG Only Label', 'Combined Label', 'RED', 'YELLOW', 'GREEN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c879e6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FF Toast Mushroom toast AAD       1\n",
       "GRL Salad Chop Chop               1\n",
       "FF Toast Smashed Avocado AAD      1\n",
       "FF Spaghetti Puttanesca AAD       1\n",
       "SL Squash bowl(1)                 1\n",
       "                                 ..\n",
       "GRL Burger Alumni AAD             1\n",
       "FF Pasta blanco AAD               1\n",
       "FLX Bao Mushroom AAD              1\n",
       "SL Maple salmon +2                1\n",
       "FF BOWL Dobanjiang Noodle AAD     1\n",
       "Name: Description, Length: 242, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All recipe items are unique as expected\n",
    "train_df['Description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9566273",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df[['Description']], train_df['Combined Label']\n",
    "X_test, y_test = test_df[['Description']], test_df['Combined Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f56c7520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FF Toast Mushroom toast AAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRL Sand Monte Cristo AAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRL Grilled Cheese Jalapeno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEL Smoothie Delish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADD Gravy 3oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>GRL Cauliflower Bites AAD 160g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>DEL Smoothie Banana Matcha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>FF Bowl OysterMushroom AAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>SL Peppercorn Pork Chop 170g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>FF BOWL Dobanjiang Noodle AAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Description\n",
       "0       FF Toast Mushroom toast AAD\n",
       "1         GRL Sand Monte Cristo AAD\n",
       "2       GRL Grilled Cheese Jalapeno\n",
       "3               DEL Smoothie Delish\n",
       "4                     ADD Gravy 3oz\n",
       "..                              ...\n",
       "237  GRL Cauliflower Bites AAD 160g\n",
       "238     DEL Smoothie Banana Matcha \n",
       "239      FF Bowl OysterMushroom AAD\n",
       "240    SL Peppercorn Pork Chop 170g\n",
       "241  FF BOWL Dobanjiang Noodle AAD \n",
       "\n",
       "[242 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41968925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Green     107\n",
       "Yellow     72\n",
       "Red        63\n",
       "Name: Combined Label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88f832db",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_metrics = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56e83402",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6468ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "#     \"\"\"\n",
    "#     Returns mean and std of cross validation\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     model :\n",
    "#         scikit-learn model\n",
    "#     X_train : numpy array or pandas DataFrame\n",
    "#         X in the training data\n",
    "#     y_train :\n",
    "#         y in the training data\n",
    "\n",
    "#     Returns\n",
    "#     ----------\n",
    "#         pandas Series with mean scores from cross_validation\n",
    "#     \"\"\"\n",
    "\n",
    "#     scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "#     mean_scores = pd.DataFrame(scores).mean()\n",
    "#     std_scores = pd.DataFrame(scores).std()\n",
    "#     out_col = []\n",
    "\n",
    "#     for i in range(len(mean_scores)):\n",
    "#         out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "#     return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33770484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.442 (+/- 0.006)</td>\n",
       "      <td>0.442 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fit_time         score_time         test_score  \\\n",
       "dummy  0.000 (+/- 0.000)  0.000 (+/- 0.000)  0.442 (+/- 0.006)   \n",
       "\n",
       "             train_score  \n",
       "dummy  0.442 (+/- 0.002)  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the baseline model\n",
    "dummy = DummyClassifier()\n",
    "results[\"dummy\"] = mean_std_cross_val_scores(\n",
    "    dummy, X_train, y_train, return_train_score=True, scoring=scoring_metrics\n",
    ")\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d7c56bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Description'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d712186a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.442 (+/- 0.006)</td>\n",
       "      <td>0.442 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.011 (+/- 0.004)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.637 (+/- 0.080)</td>\n",
       "      <td>0.966 (+/- 0.008)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              fit_time         score_time         test_score  \\\n",
       "dummy                0.000 (+/- 0.000)  0.000 (+/- 0.000)  0.442 (+/- 0.006)   \n",
       "logistic regression  0.011 (+/- 0.004)  0.000 (+/- 0.000)  0.637 (+/- 0.080)   \n",
       "\n",
       "                           train_score  \n",
       "dummy                0.442 (+/- 0.002)  \n",
       "logistic regression  0.966 (+/- 0.008)  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Code without Cross-validation yet\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# pipe = make_pipeline(CountVectorizer(stop_words='english'), \n",
    "#                      LogisticRegression(max_iter=1000))\n",
    "# results[\"logistic regression\"] = mean_std_cross_val_scores(\n",
    "#     pipe, X_train['Description'], y_train, return_train_score=True, scoring=scoring_metrics\n",
    "# )\n",
    "# pd.DataFrame(results).T\n",
    "\n",
    "\n",
    "# Code without Cross-validation yet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "pipe = make_pipeline(CountVectorizer(stop_words='english'), \n",
    "                     LogisticRegression(max_iter=1000))\n",
    "results[\"logistic regression\"] = mean_std_cross_val_scores(\n",
    "    pipe, X_train['Description'], y_train, return_train_score=True, scoring=scoring_metrics\n",
    ")\n",
    "pd.DataFrame(results).T\n",
    "\n",
    "\n",
    "\n",
    "# scoring_metric = \"accuracy\"\n",
    "# param_grid = {\"C\": np.logspace(-5, 5, 11)}\n",
    "# for param in param_grid[\"C\"]:\n",
    "#     model_name = \"Logistic Regression\"\n",
    "#     pipe = make_pipeline(CountVectorizer(stop_words='english'), LogisticRegression(C=param, max_iter=1000))\n",
    "\n",
    "#     key = model_name + \"(C= \" + str(param) + \")\"\n",
    "#     results[key] = mean_std_cross_val_scores(\n",
    "#         pipe, X_train, y_train, cv=5, return_train_score=True, scoring = scoring_metric\n",
    "#     )\n",
    "\n",
    "# results_df = pd.DataFrame(results).T\n",
    "# results_df\n",
    "\n",
    "# scoring_metric = \"accuracy\"\n",
    "# param_grid = {\"C\": np.logspace(-5, 5, 11)}\n",
    "# results = {}\n",
    "\n",
    "# # Convert text data using CountVectorizer\n",
    "# vectorizer = CountVectorizer(stop_words='english')\n",
    "# X_train_vectorized = vectorizer.fit_transform(X_train['Description'])\n",
    "\n",
    "# for param in param_grid[\"C\"]:\n",
    "#     model_name = \"Logistic Regression\"\n",
    "#     pipe = make_pipeline(vectorizer, LogisticRegression(C=param, max_iter=1000))\n",
    "\n",
    "#     key = model_name + \"(C= \" + str(param) + \")\"\n",
    "#     results[key] = mean_std_cross_val_scores(\n",
    "#         pipe, X_train_vectorized, y_train, cv=5, return_train_score=True, scoring=scoring_metric\n",
    "#     )\n",
    "\n",
    "# results_df = pd.DataFrame(results).T\n",
    "# results_df\n",
    "\n",
    "# scoring_metric = \"accuracy\"\n",
    "# param_grid = {\"C\": np.logspace(-5, 5, 11)}\n",
    "# results = {}\n",
    "\n",
    "# # Convert text data using TfidfVectorizer\n",
    "# vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# X_train_vectorized = vectorizer.fit_transform(X_train['Description'])\n",
    "\n",
    "# for param in param_grid[\"C\"]:\n",
    "#     model_name = \"Logistic Regression\"\n",
    "#     pipe = make_pipeline(vectorizer, LogisticRegression(C=param, max_iter=1000))\n",
    "\n",
    "#     key = model_name + \"(C= \" + str(param) + \")\"\n",
    "#     results[key] = mean_std_cross_val_scores(\n",
    "#         pipe, X_train_vectorized, y_train, cv=5, return_train_score=True, scoring=scoring_metric\n",
    "#     )\n",
    "\n",
    "# results_df = pd.DataFrame(results).T\n",
    "# results_df\n",
    "\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3291bbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132    Yellow\n",
       "202       Red\n",
       "196       Red\n",
       "75     Yellow\n",
       "176     Green\n",
       "        ...  \n",
       "188     Green\n",
       "71      Green\n",
       "106     Green\n",
       "270       Red\n",
       "102     Green\n",
       "Name: Combined Label, Length: 242, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "273d9cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a popular library called nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cf537b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b847d6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3oz</th>\n",
       "      <th>aad</th>\n",
       "      <th>acorn</th>\n",
       "      <th>add</th>\n",
       "      <th>albacore</th>\n",
       "      <th>almonds</th>\n",
       "      <th>alumni</th>\n",
       "      <th>apple</th>\n",
       "      <th>applecin</th>\n",
       "      <th>asparagus</th>\n",
       "      <th>...</th>\n",
       "      <th>wilted</th>\n",
       "      <th>wing</th>\n",
       "      <th>wise</th>\n",
       "      <th>wrap</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>yaki</th>\n",
       "      <th>yam</th>\n",
       "      <th>zinger</th>\n",
       "      <th>zuc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Description</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FF Toast Mushroom toast AAD</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRL Sand Monte Cristo AAD</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRL Grilled Cheese Jalapeno</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEL Smoothie Delish</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADD Gravy 3oz</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRL Cauliflower Bites AAD 160g</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEL Smoothie Banana Matcha</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FF Bowl OysterMushroom AAD</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SL Peppercorn Pork Chop 170g</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FF BOWL Dobanjiang Noodle AAD</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                3oz  aad  acorn  add  albacore  almonds  \\\n",
       "Description                                                               \n",
       "FF Toast Mushroom toast AAD       0    1      0    0         0        0   \n",
       "GRL Sand Monte Cristo AAD         0    1      0    0         0        0   \n",
       "GRL Grilled Cheese Jalapeno       0    0      0    0         0        0   \n",
       "DEL Smoothie Delish               0    0      0    0         0        0   \n",
       "ADD Gravy 3oz                     1    0      0    1         0        0   \n",
       "...                             ...  ...    ...  ...       ...      ...   \n",
       "GRL Cauliflower Bites AAD 160g    0    1      0    0         0        0   \n",
       "DEL Smoothie Banana Matcha        0    0      0    0         0        0   \n",
       "FF Bowl OysterMushroom AAD        0    1      0    0         0        0   \n",
       "SL Peppercorn Pork Chop 170g      0    0      0    0         0        0   \n",
       "FF BOWL Dobanjiang Noodle AAD     0    1      0    0         0        0   \n",
       "\n",
       "                                alumni  apple  applecin  asparagus  ...  \\\n",
       "Description                                                         ...   \n",
       "FF Toast Mushroom toast AAD          0      0         0          0  ...   \n",
       "GRL Sand Monte Cristo AAD            0      0         0          0  ...   \n",
       "GRL Grilled Cheese Jalapeno          0      0         0          0  ...   \n",
       "DEL Smoothie Delish                  0      0         0          0  ...   \n",
       "ADD Gravy 3oz                        0      0         0          0  ...   \n",
       "...                                ...    ...       ...        ...  ...   \n",
       "GRL Cauliflower Bites AAD 160g       0      0         0          0  ...   \n",
       "DEL Smoothie Banana Matcha           0      0         0          0  ...   \n",
       "FF Bowl OysterMushroom AAD           0      0         0          0  ...   \n",
       "SL Peppercorn Pork Chop 170g         0      0         0          0  ...   \n",
       "FF BOWL Dobanjiang Noodle AAD        0      0         0          0  ...   \n",
       "\n",
       "                                wilted  wing  wise  wrap  x1  x2  yaki  yam  \\\n",
       "Description                                                                   \n",
       "FF Toast Mushroom toast AAD          0     0     0     0   0   0     0    0   \n",
       "GRL Sand Monte Cristo AAD            0     0     0     0   0   0     0    0   \n",
       "GRL Grilled Cheese Jalapeno          0     0     0     0   0   0     0    0   \n",
       "DEL Smoothie Delish                  0     0     0     0   0   0     0    0   \n",
       "ADD Gravy 3oz                        0     0     0     0   0   0     0    0   \n",
       "...                                ...   ...   ...   ...  ..  ..   ...  ...   \n",
       "GRL Cauliflower Bites AAD 160g       0     0     0     0   0   0     0    0   \n",
       "DEL Smoothie Banana Matcha           0     0     0     0   0   0     0    0   \n",
       "FF Bowl OysterMushroom AAD           0     0     0     0   0   0     0    0   \n",
       "SL Peppercorn Pork Chop 170g         0     0     0     0   0   0     0    0   \n",
       "FF BOWL Dobanjiang Noodle AAD        0     0     0     0   0   0     0    0   \n",
       "\n",
       "                                zinger  zuc  \n",
       "Description                                  \n",
       "FF Toast Mushroom toast AAD          0    0  \n",
       "GRL Sand Monte Cristo AAD            0    0  \n",
       "GRL Grilled Cheese Jalapeno          0    0  \n",
       "DEL Smoothie Delish                  0    0  \n",
       "ADD Gravy 3oz                        0    0  \n",
       "...                                ...  ...  \n",
       "GRL Cauliflower Bites AAD 160g       0    0  \n",
       "DEL Smoothie Banana Matcha           0    0  \n",
       "FF Bowl OysterMushroom AAD           0    0  \n",
       "SL Peppercorn Pork Chop 170g         0    0  \n",
       "FF BOWL Dobanjiang Noodle AAD        0    0  \n",
       "\n",
       "[242 rows x 296 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# # CountVectorizer creates a bag of words for us\n",
    "# vec = CountVectorizer(stop_words='english')\n",
    "# X_counts = vec.fit_transform(X_train[\"Description\"])\n",
    "# bow_df = pd.DataFrame(\n",
    "#     X_counts.toarray(), columns=vec.get_feature_names_out(), index=X_train[\"Description\"]\n",
    "# )\n",
    "\n",
    "# # Each column represents a word in the vocabulary (set of unique words)\n",
    "\n",
    "# bow_df\n",
    "\n",
    "import re\n",
    "\n",
    "# Fit the CountVectorizer on the training data\n",
    "# vec = CountVectorizer(stop_words='english')\n",
    "# X_counts = vec.fit_transform(X_train[\"Description\"])\n",
    "\n",
    "# # Remove measurements and other patterns from the feature names\n",
    "# feature_names = vec.get_feature_names_out()\n",
    "# clean_feature_names = [re.sub(r'\\d+g|\\+\\d+|__ g|\\(.*\\)', '', feature) for feature in feature_names]\n",
    "\n",
    "# # Create a DataFrame with the cleaned feature names\n",
    "# bow_df = pd.DataFrame(X_counts.toarray(), columns=clean_feature_names, index=X_train[\"Description\"])\n",
    "\n",
    "\n",
    "# bow_df\n",
    "\n",
    "\n",
    "# import re\n",
    "\n",
    "# Fit the CountVectorizer on the training data\n",
    "vec = CountVectorizer(stop_words='english')\n",
    "X_counts = vec.fit_transform(X_train[\"Description\"])\n",
    "\n",
    "# Remove measurements and other patterns from the feature names\n",
    "feature_names = vec.get_feature_names_out()\n",
    "clean_feature_names = [re.sub(r'\\d+g|\\+\\d+|\\d+ml|__ g|\\(.*\\)', '', feature) for feature in feature_names]\n",
    "\n",
    "\n",
    "# Create a DataFrame with the cleaned feature names\n",
    "bow_df = pd.DataFrame(X_counts.toarray(), columns=clean_feature_names, index=X_train[\"Description\"])\n",
    "\n",
    "# index=X_train.index\n",
    "\n",
    "# Remove the unwanted columns from the DataFrame\n",
    "unwanted_columns = [col for col in bow_df.columns if not col.strip()]\n",
    "bow_df.drop(columns=unwanted_columns, inplace=True)\n",
    "\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ada0d938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aad         99\n",
      "sl          52\n",
      "grl         50\n",
      "bowl        44\n",
      "ff          34\n",
      "flx         29\n",
      "cal         26\n",
      "chicken     21\n",
      "del         19\n",
      "salad       17\n",
      "salmon      15\n",
      "beef        13\n",
      "burger      13\n",
      "toast       12\n",
      "pork        11\n",
      "taco        11\n",
      "gza         11\n",
      "kombucha    10\n",
      "bev         10\n",
      "veg          8\n",
      "smoothie     8\n",
      "benny        8\n",
      "herb         8\n",
      "cheese       7\n",
      "squash       7\n",
      "tofu         6\n",
      "mushroom     6\n",
      "pasta        6\n",
      "thigh        6\n",
      "soup         6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find the count of each keyword\n",
    "keyword_counts = bow_df.sum(axis=0)\n",
    "\n",
    "# Sort the keyword counts in descending order\n",
    "keyword_counts_sorted = keyword_counts.sort_values(ascending=False)\n",
    "\n",
    "# Print the keyword counts in descending order\n",
    "print(keyword_counts_sorted.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f919a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer can only take one column and not a data table\n",
    "type(X_train[\"Description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8effa61",
   "metadata": {},
   "source": [
    "***Important***\n",
    "Note that unlike other transformers we are **passing a `Series`** object to `fit_transform`. For other transformers, we can define one transformer for more than one columns. But with `CountVectorizer` we need to define **separate `CountVectorizer` transformers for each text column**, if we have more than one text columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b49c4e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<242x305 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1023 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bf8542c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows and columns:  242 305\n",
      "The total number of elements:  73810\n",
      "The number of non-zero elements:  1023\n",
      "Proportion of non-zero elements: 0.0139\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of rows and columns: \", *X_counts.shape)\n",
    "print(\"The total number of elements: \", np.prod(X_counts.shape))\n",
    "print(\"The number of non-zero elements: \", X_counts.nnz)\n",
    "print(\n",
    "    \"Proportion of non-zero elements: %0.4f\" % (X_counts.nnz / np.prod(X_counts.shape))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e41726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bca932d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [241, 242]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m logistic_model \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m \u001b[43mlogistic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Evaluate the model on test data\u001b[39;00m\n\u001b[0;32m     41\u001b[0m test_sentences \u001b[38;5;241m=\u001b[39m [nltk\u001b[38;5;241m.\u001b[39mword_tokenize(sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1196\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1124\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1124\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [241, 242]"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Reindex the train_df DataFrame\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "# Preprocess the text\n",
    "sentences = [nltk.word_tokenize(sentence) for sentence in train_df['Description']]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# Convert text data into numerical vectors\n",
    "word_vectors = model.wv\n",
    "sentence_vectors = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    vectors = []\n",
    "    for word in sentence:\n",
    "        if word in word_vectors:\n",
    "            vectors.append(word_vectors[word])\n",
    "    if vectors:\n",
    "        sentence_vector = sum(vectors) / len(vectors)  # Averaging word vectors\n",
    "        sentence_vectors.append(sentence_vector)\n",
    "\n",
    "# Train your classification model (e.g., logistic regression)\n",
    "X_train = np.vstack(sentence_vectors)\n",
    "y_train = train_df['Combined Label']\n",
    "\n",
    "# Reindex X_train and y_train\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train_df, y_train)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_sentences = [nltk.word_tokenize(sentence) for sentence in test_df['Description']]\n",
    "test_sentence_vectors = []\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    vectors = []\n",
    "    for word in sentence:\n",
    "        if word in word_vectors:\n",
    "            vectors.append(word_vectors[word])\n",
    "    if vectors:\n",
    "        sentence_vector = sum(vectors) / len(vectors)\n",
    "        test_sentence_vectors.append(sentence_vector)\n",
    "\n",
    "X_test = np.vstack(test_sentence_vectors)\n",
    "y_test = test_df['Combined Label']\n",
    "accuracy = logistic_model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f59b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# pipe = make_pipeline(CountVectorizer(stop_words='english'), \n",
    "#                      LogisticRegression(max_iter=1000))\n",
    "# results[\"logistic regression\"] = mean_std_cross_val_scores(\n",
    "#     pipe, bow_df, y_train, return_train_score=True, scoring=scoring_metrics\n",
    "# )\n",
    "# pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69eabd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a CountVectorizer instance and fit it on the training data\n",
    "# vectorizer = CountVectorizer(stop_words='english')\n",
    "# X_train_counts = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd52e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transform the testing data using the trained vectorizer\n",
    "# X_test_counts = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a569e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train a classifier (e.g., Naive Bayes) on the training data\n",
    "# classifier = MultinomialNB()\n",
    "# classifier.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e9d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make predictions on the testing data\n",
    "# y_pred = classifier.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cdf8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the performance of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
